# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1, 1),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1.1, 1),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1.1, 1.5),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1.1, -1),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1, -1),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1, -0.8),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1, 0),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1, -0.5),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1, -0.5),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
plot.roc(svm_POLY_fit$pred$obs[idx_POLY], svm_POLY_fit$pred$No[idx_POLY],
col = "purple",
print.thres = FALSE,
print.auc = TRUE,
print.auc.x = 1, print.auc.y = 0.93,
add = TRUE)
plot.roc(svm_LINEAR_fit$pred$obs[idx_LINEAR], svm_LINEAR_fit$pred$No[idx_LINEAR],
col = "red",
print.thres = FALSE,
print.auc = TRUE,
print.auc.x = 1, print.auc.y = 0.88,
add = TRUE)
grid()
# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1.1, -0.5),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1.05, -0.5),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
plot.roc(svm_POLY_fit$pred$obs[idx_POLY], svm_POLY_fit$pred$No[idx_POLY],
col = "purple",
print.thres = FALSE,
print.auc = TRUE,
print.auc.x = 1, print.auc.y = 0.93,
add = TRUE)
plot.roc(svm_LINEAR_fit$pred$obs[idx_LINEAR], svm_LINEAR_fit$pred$No[idx_LINEAR],
col = "red",
print.thres = FALSE,
print.auc = TRUE,
print.auc.x = 1, print.auc.y = 0.88,
add = TRUE)
grid()
# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1, -0.5),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1.08, -0.5),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1.025, -0.5),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1.05, -0.5),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
# Visualizzo le curve ROC dei modelli con kernel lineare, RBF e polinomiale di quarto grado
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1.025, -0.5),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
pdf(file = "roc_performance.pdf", height = hh, width = ww,  pointsize = 8)
plot.roc(svm_RBF_fit$pred$obs[idx_RBF], svm_RBF_fit$pred$No[idx_RBF],
col = "orange", axes = TRUE,
print.thres = TRUE, print.thres.adj = c(1.025, -0.5),
print.auc = TRUE, auc.polygon = TRUE,
print.auc.x = 1, print.auc.y = 0.98, asp = 0.8,
main = "Confronto funzioni kernel - ROC")
plot.roc(svm_POLY_fit$pred$obs[idx_POLY], svm_POLY_fit$pred$No[idx_POLY],
col = "purple",
print.thres = FALSE,
print.auc = TRUE,
print.auc.x = 1, print.auc.y = 0.93,
add = TRUE)
plot.roc(svm_LINEAR_fit$pred$obs[idx_LINEAR], svm_LINEAR_fit$pred$No[idx_LINEAR],
col = "red",
print.thres = FALSE,
print.auc = TRUE,
print.auc.x = 1, print.auc.y = 0.88,
add = TRUE)
grid()
dev.off()
dev.off()
svm_RBF_fit
svm_RBF_fit$results
svm_RBF_fit$results[, 1:5]
################################################################################
# Salvataggi tabelle
pdf(file = "svm_RBF_fit.pdf", height = hh, width = ww,  pointsize = 8)
svm_RBF_fit$results[, 1:5]
dev.off()
svm_POLY_fit$results[, 1:5]
svm_POLY_fit$results[, 1:6]
svm_POLY_fit$results[, 1:7]
svm_POLY_fit$results[, 1:6]
svm_LINEAR_fit$results[, 1:6]
svm_LINEAR_fit$results[, 1:5]
svm_LINEAR_fit$results[, 1:4]
?plot.roc
svm_RBF_fit
load("SVM script (workspace image).RData")
get_f1 <- function(svm_fit){
to_return <- matrix(data = rep(0, 100), nrow = 10)
for(i in 1:10){
for(j in 1:10){
# Compongo la stringa per prelevare i risultati desiderati
str1 <- sprintf("%02d", i)
str2 <- sprintf("%02d", j)
fold <- paste0("Fold", str1, ".", "Rep", str2)
#print(fold)
# Seleziono i risultati
idx <- svm_fit$pred$Resample == fold
svm_fold <- svm_fit$pred[idx, ]
# Matrice di confusione
#   - positive specifica la classe da considerare come positiva
#   - mode = "prec_recall" fa in modo che venga restituito lo score F1
confmat <- confusionMatrix(data = svm_fold$pred,
reference = svm_fold$obs,
positive = "Yes", mode = "prec_recall")
to_return[i, j] <- confmat$byClass[7]
#print(to_return[i, j])
}
}
return(to_return)
}
f1_RBF <- get_f1(svm_RBF_fit)
library(e1071)
library(dplyr)
library(caret)
library(factoextra)
library(MLeval)
f1_RBF <- get_f1(svm_RBF_fit)
f1_RBF
plot(x = 1:100, y = f1_RBF, t="l", main = "F-score", xlab = "index", ylab = "F1")
abline(h = mean(f1), col = "red")
abline(h = mean(f1_RBF), col = "red")
f1_POLY <- get_f1(svm_POLY_fit)
f1_POLY
plot(x = 1:100, y = f1_POLY, t="l", main = "F-score", xlab = "index", ylab = "F1")
abline(h = mean(f1_POLY), col = "red")
f1_LINEAR <- get_f1(svm_LINEAR_fit)
f1_LINEAR
plot(x = 1:100, y = f1_LINEAR, t="l", main = "F-score", xlab = "index", ylab = "F1")
abline(h = mean(f1_LINEAR), col = "red")
plot(x = 1:100, y = f1_LINEAR, t="l", col = "orange", t = "b", lwd = 2,
main = "F-score", xlab = "index", ylab = "F1")
plot(x = 1:100, y = f1_LINEAR, t="b", col = "orange", lwd = 2,
main = "F-score", xlab = "index", ylab = "F1")
abline(h = mean(f1_LINEAR), col = "")
abline(h = mean(f1_LINEAR), col = "orange")
lines(x = 1:100, y = f1_POLY, t="b", col = "purple", lwd = 2)
abline(h = mean(f1_POLY), col = "purple")
plot(x = 1:100, y = f1_LINEAR, t="l", col = "red", lwd = 2,
main = "F-score", xlab = "index", ylab = "F1")
abline(h = mean(f1_LINEAR), col = "red")
lines(x = 1:100, y = f1_POLY, t="l", col = "purple", lwd = 2)
abline(h = mean(f1_POLY), col = "purple")
lines(x = 1:100, y = f1_RBF, t="l", col = "orange", lwd = 2)
abline(h = mean(f1_RBF), col = "orange")
abline(h = mean(f1_LINEAR), col = "red", lwd = 2)
range(f1_RBF)
range(f1_POLY)
range(f1_LINEAR)
plot(x = 1:100, y = f1_LINEAR, t="l", col = "red", lwd = 1,
main = "F-score", xlab = "index", ylab = "F1", ylim = c(0.04, 0.30))
abline(h = mean(f1_LINEAR), col = "red", lwd = 2)
lines(x = 1:100, y = f1_POLY, t="l", col = "purple", lwd = 1)
abline(h = mean(f1_POLY), col = "purple", lwd = 2)
lines(x = 1:100, y = f1_RBF, t="l", col = "orange", lwd = 1)
abline(h = mean(f1_RBF), col = "orange", lwd = 2)
plot(x = 1:100, y = f1_LINEAR, t="l", col = "red", lwd = 1,
main = "Mean F-score", xlab = "index", ylab = "F1", ylim = c(0.04, 0.30))
abline(h = mean(f1_LINEAR), col = "red", lwd = 2)
lines(x = 1:100, y = f1_POLY, t="l", col = "purple", lwd = 1)
abline(h = mean(f1_POLY), col = "purple", lwd = 2)
lines(x = 1:100, y = f1_RBF, t="l", col = "orange", lwd = 1)
abline(h = mean(f1_RBF), col = "orange", lwd = 2)
legend(x = "topleft", legend = c("Linear", "Poly d = 4", "RBF"),
col = c("red", "purple", "orange"), lwd = 2)
grid()
plot(x = 1:100, y = f1_LINEAR, t="l", col = "red", lwd = 1,
main = "Mean F-score", xlab = "index", ylab = "F1", ylim = c(0.04, 0.30))
abline(h = mean(f1_LINEAR), col = "red", lwd = 2)
lines(x = 1:100, y = f1_POLY, t="l", col = "purple", lwd = 1)
abline(h = mean(f1_POLY), col = "purple", lwd = 2)
lines(x = 1:100, y = f1_RBF, t="l", col = "orange", lwd = 1)
abline(h = mean(f1_RBF), col = "orange", lwd = 2)
grid()
legend(x = "topleft", legend = c("Linear", "Poly d = 4", "RBF"),
col = c("red", "purple", "orange"), lwd = 2)
?mcc
svm_RBF_fit$pred
mcc(svm_RBF_fit$pred$obs, svm_RBF_fit$pred$pred)
library(ModelMetrics)
mcc(svm_RBF_fit$pred$obs, svm_RBF_fit$pred$pred)
# Curva F-score funzioni kernel
pdf(file = "fscore_performance.pdf", height = hh, width = ww,  pointsize = 8)
ar <- sqrt(2)
h <- 110
hh <- h / 25.4
ww <- hh * ar
pdf(file = "fscore_performance.pdf", height = hh, width = ww,  pointsize = 8)
plot(x = 1:100, y = f1_LINEAR, t="l", col = "red", lwd = 1,
main = "Mean F-score", xlab = "index", ylab = "F1", ylim = c(0.04, 0.30))
abline(h = mean(f1_LINEAR), col = "red", lwd = 2)
lines(x = 1:100, y = f1_POLY, t="l", col = "purple", lwd = 1)
abline(h = mean(f1_POLY), col = "purple", lwd = 2)
lines(x = 1:100, y = f1_RBF, t="l", col = "orange", lwd = 1)
abline(h = mean(f1_RBF), col = "orange", lwd = 2)
grid()
legend(x = "topleft", legend = c("Linear", "Poly d = 4", "RBF"),
col = c("red", "purple", "orange"), lwd = 2)
dev.off()
# PROVA
fold <- "Fold1.Rep1"
print(fold)
# Seleziono i risultati
idx <- svm_RBF_fit$pred$Resample == fold
# Seleziono i risultati
idx <- svm_RBF_fit$pred$Resample == fold
idx
svm_fold <- svm_RBF_fit$pred[idx, ]
svm_fold
svm_RBF_fit$pred$Resample
# PROVA
fold <- "Fold01.Rep01"
print(fold)
# Seleziono i risultati
idx <- svm_RBF_fit$pred$Resample == fold
svm_fold <- svm_RBF_fit$pred[idx, ]
svm_fold
# Matrice di confusione
#   - positive specifica la classe da considerare come positiva
#   - mode = "prec_recall" fa in modo che venga restituito lo score F1
confmat <- confusionMatrix(data = svm_fold$pred,
reference = svm_fold$obs,
positive = "Yes", mode = "prec_recall")
# Matrice di confusione
#   - positive specifica la classe da considerare come positiva
#   - mode = "prec_recall" fa in modo che venga restituito lo score F1
confmat <- confusionMatrix(data = svm_fold$pred,
reference = svm_fold$obs)
?confusionMatrix
# Matrice di confusione
#   - positive specifica la classe da considerare come positiva
#   - mode = "prec_recall" fa in modo che venga restituito lo score F1
confmat <- caret::confusionMatrix(data = svm_fold$pred,
reference = svm_fold$obs,
positive = "Yes", mode = "prec_recall")
confmat
confmat$byClass
fold <- "Fold01.Rep02"
print(fold)
# Seleziono i risultati
idx <- svm_RBF_fit$pred$Resample == fold
svm_fold <- svm_RBF_fit$pred[idx, ]
# Matrice di confusione
#   - positive specifica la classe da considerare come positiva
#   - mode = "prec_recall" fa in modo che venga restituito lo score F1
confmat <- caret::confusionMatrix(data = svm_fold$pred,
reference = svm_fold$obs,
positive = "Yes", mode = "prec_recall")
confmat$byClass
# PROVA
fold <- "Fold01.Rep01"
print(fold)
# Seleziono i risultati
idx <- svm_POLY_fit$pred$Resample == fold
svm_fold <- svm_POLY_fit$pred[idx, ]
# Matrice di confusione
#   - positive specifica la classe da considerare come positiva
#   - mode = "prec_recall" fa in modo che venga restituito lo score F1
confmat <- caret::confusionMatrix(data = svm_fold$pred,
reference = svm_fold$obs,
positive = "Yes", mode = "prec_recall")
confmat$byClass
rm(get_f1)
get_prec_rec <- function(svm_fit){
to_return <- list(Precision = matrix(data = rep(0, 100), nrow = 10),
Recall = matrix(data = rep(0, 100), nrow = 10))
for(i in 1:10){
for(j in 1:10){
# Compongo la stringa per prelevare i risultati desiderati
str1 <- sprintf("%02d", i)
str2 <- sprintf("%02d", j)
fold <- paste0("Fold", str1, ".", "Rep", str2)
#print(fold)
# Seleziono i risultati
idx <- svm_fit$pred$Resample == fold
svm_fold <- svm_fit$pred[idx, ]
# Matrice di confusione
#   - positive specifica la classe da considerare come positiva
#   - mode = "prec_recall" fa in modo che venga restituito lo score F1
confmat <- caret::confusionMatrix(data = svm_fold$pred,
reference = svm_fold$obs,
positive = "Yes", mode = "prec_recall")
to_return$Precision[i, j] <- confmat$byClass[5]
to_return$Recall[i, j] <- confmat$byClass[6]
}
}
return(to_return)
}
prec_rec_LINEAR <- get_prec_rec(svm_LINEAR_fit)
prec_rec_POLY <- get_prec_rec(svm_POLY_fit)
prec_rec_RBF <- get_prec_rec(svm_RBF_fit)
prec_rec_LINEAR$Precision
plot(x = prec_rec_LINEAR$Precision, y = prec_rec_LINEAR$Recall)
plot(x = prec_rec_LINEAR$Precision, y = prec_rec_LINEAR$Recall, t="l")
rm(get_prec_rec())
rm(get_prec_rec)
################################################################################
# Prelevo gli Precision e Recall da ogni modello
get_rec <- function(svm_fit){
to_return <- matrix(data = rep(0, 100), nrow = 10)
for(i in 1:10){
for(j in 1:10){
# Compongo la stringa per prelevare i risultati desiderati
str1 <- sprintf("%02d", i)
str2 <- sprintf("%02d", j)
fold <- paste0("Fold", str1, ".", "Rep", str2)
#print(fold)
# Seleziono i risultati
idx <- svm_fit$pred$Resample == fold
svm_fold <- svm_fit$pred[idx, ]
# Matrice di confusione
#   - positive specifica la classe da considerare come positiva
#   - mode = "prec_recall" fa in modo che venga restituito lo score F1
confmat <- caret::confusionMatrix(data = svm_fold$pred,
reference = svm_fold$obs,
positive = "Yes", mode = "prec_recall")
to_return[i, j] <- confmat$byClass[6]
}
}
return(to_return)
}
get_rec <- function(svm_fit){
to_return <- matrix(data = rep(0, 100), nrow = 10)
for(i in 1:10){
for(j in 1:10){
# Compongo la stringa per prelevare i risultati desiderati
str1 <- sprintf("%02d", i)
str2 <- sprintf("%02d", j)
fold <- paste0("Fold", str1, ".", "Rep", str2)
#print(fold)
# Seleziono i risultati
idx <- svm_fit$pred$Resample == fold
svm_fold <- svm_fit$pred[idx, ]
# Matrice di confusione
#   - positive specifica la classe da considerare come positiva
#   - mode = "prec_recall" fa in modo che venga restituito lo score F1
confmat <- caret::confusionMatrix(data = svm_fold$pred,
reference = svm_fold$obs,
positive = "Yes", mode = "prec_recall")
to_return[i, j] <- confmat$byClass[6]
}
}
return(to_return)
}
rec_LINEAR <- get_rec(svm_LINEAR_fit)
rec_POLY <- get_rec(svm_POLY_fit)
rec_RBF <- get_rec(svm_RBF_fit)
rec_RBF
plot(x = 1:100, y = rec_LINEAR, t="l")
# Visualizzo i risultati
plot(x = 1:100, y = rec_LINEAR, t="l", col = "red", lwd = 1,
main = "Mean F-score", xlab = "index", ylab = "Recall", ylim = c(0.04, 0.30))
abline(h = mean(rec_LINEAR), col = "red", lwd = 2)
lines(x = 1:100, y = rec_POLY, t="l", col = "purple", lwd = 1)
abline(h = mean(rec_POLY), col = "purple", lwd = 2)
lines(x = 1:100, y = rec_RBF, t="l", col = "orange", lwd = 1)
abline(h = mean(rec_RBF), col = "orange", lwd = 2)
grid()
legend(x = "topleft", legend = c("Linear", "Poly d = 4", "RBF"),
col = c("red", "purple", "orange"), lwd = 2)
# Visualizzo i risultati
plot(x = 1:100, y = rec_LINEAR, t="l", col = "red", lwd = 1,
main = "Mean F-score", xlab = "index", ylab = "Recall")
abline(h = mean(rec_LINEAR), col = "red", lwd = 2)
lines(x = 1:100, y = rec_POLY, t="l", col = "purple", lwd = 1)
abline(h = mean(rec_POLY), col = "purple", lwd = 2)
lines(x = 1:100, y = rec_RBF, t="l", col = "orange", lwd = 1)
abline(h = mean(rec_RBF), col = "orange", lwd = 2)
grid()
legend(x = "topleft", legend = c("Linear", "Poly d = 4", "RBF"),
col = c("red", "purple", "orange"), lwd = 2)
# Visualizzo i risultati
plot(x = 1:100, y = rec_LINEAR, t="l", col = "red", lwd = 2,
main = "Mean F-score", xlab = "index", ylab = "Recall")
#abline(h = mean(rec_LINEAR), col = "red", lwd = 2)
lines(x = 1:100, y = rec_POLY, t="l", col = "purple", lwd = 2)
#abline(h = mean(rec_POLY), col = "purple", lwd = 2)
lines(x = 1:100, y = rec_RBF, t="l", col = "orange", lwd = 2)
#abline(h = mean(rec_RBF), col = "orange", lwd = 2)
grid()
legend(x = "topleft", legend = c("Linear", "Poly d = 4", "RBF"),
col = c("red", "purple", "orange"), lwd = 2)
svm_RBF_fit
confmat <- caret::confusionMatrix(data = svm_fold$pred,
reference = svm_fold$obs,
positive = "Yes", mode = "prec_recall")
confmat$byClass
# PROVA
fold <- "Fold01.Rep01"
print(fold)
# Seleziono i risultati
idx <- svm_RBF_fit$pred$Resample == fold
svm_fold <- svm_RBF_fit$pred[idx, ]
# Matrice di confusione
#   - positive specifica la classe da considerare come positiva
#   - mode = "prec_recall" fa in modo che venga restituito lo score F1
confmat <- caret::confusionMatrix(data = svm_fold$pred,
reference = svm_fold$obs,
positive = "Yes", mode = "prec_recall")
confmat$byClass
table(dat5$class)
table(dat5$class)/nrow(dat5)
cv
load("SvM script (da eseguire).RData")
load("SvM script (workspace image).RData")
# Analisi correlazioni
cor(dat5[, 1:64]) > 0.8
# PCA
pc <- prcomp(dat5[, 1:64], center = TRUE)
fviz_eig(pc, addlabels = TRUE)
l <- pc$sdev^2
cv <- cumsum(l)/sum(l)*100
cv
plot(l/sum(l)*100, t = 'l', col = 2, lwd = 2,
ylab = "Varianza [%]",
xlab = "Componente")
grid()
k <- min( which(cv >= 99) )
dat5 <- read.csv("5year.csv")
dim(dat5)
dat5
dat5
